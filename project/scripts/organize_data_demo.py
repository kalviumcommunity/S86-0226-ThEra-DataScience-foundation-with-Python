"""Demonstration script for data organization milestone.

Reads raw data, performs a trivial transformation, and saves
results in the processed folder. Also writes a simple output
artifact in the outputs directory.
"""
import csv
from pathlib import Path

# define directories relative to project root
BASE = Path(__file__).resolve().parents[1]
RAW_DIR = BASE / "data" / "raw"
PROC_DIR = BASE / "data" / "processed"
OUT_DIR = BASE / "outputs"

# ensure directories exist (they should already, but this is safe)
FOR_DIRS = [RAW_DIR, PROC_DIR, OUT_DIR]
for d in FOR_DIRS:
    d.mkdir(parents=True, exist_ok=True)

# read the example raw file and perform a trivial transformation
raw_file = RAW_DIR / "example_raw.csv"
processed_rows = []
with open(raw_file, newline="") as csvfile:
    reader = csv.DictReader(csvfile)
    for row in reader:
        # double the value field
        row["value_double"] = str(int(row["value"]) * 2)
        processed_rows.append(row)

# save to processed folder without touching raw data
processed_file = PROC_DIR / "example_processed.csv"
with open(processed_file, "w", newline="") as csvfile:
    fieldnames = ["id", "value", "value_double"]
    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
    writer.writeheader()
    writer.writerows(processed_rows)

# create an output artifact (a short report)
with open(OUT_DIR / "readme.txt", "w") as f:
    f.write(
        "This outputs folder contains artifacts generated by scripts.\n"
        "Raw data lives in data/raw, processed data in data/processed.\n"
    )

print(f"Raw data   : {raw_file}")
print(f"Processed  : {processed_file}")
print(f"Output note: {OUT_DIR / 'readme.txt'}")
